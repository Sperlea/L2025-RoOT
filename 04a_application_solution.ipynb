{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cb09f18",
   "metadata": {},
   "source": [
    "In this part of our course, we will apply the model you trained before to new data. We'll start by reusing some of the code you've seen before, slightly adapted to a new folder structure. We'll save the resulting vectors via pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5079ab89",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 57\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[1;32m     56\u001b[0m super_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/sperlea/Desktop/project_auto_microscopy/scripts/playground/data/IFCBpics/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 57\u001b[0m all_images \u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root, f) \u001b[38;5;28;01mfor\u001b[39;00m root, dirs, files \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mwalk(super_folder) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m files \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m f]\n\u001b[1;32m     58\u001b[0m df \u001b[38;5;241m=\u001b[39m get_image_embeddings(all_images)\n\u001b[1;32m     59\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(df, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/sperlea/Desktop/project_auto_microscopy/scripts/playground/data/embedded_photos.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "def get_image_embeddings(image_list,\n",
    "                         model=None,\n",
    "                         exts=('jpg', 'jpeg', 'png', 'bmp', 'tiff')):\n",
    "    \"\"\"\n",
    "    Given a list of folder paths, returns a DataFrame of image embeddings with class labels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_list : list of str\n",
    "        List of paths to images.\n",
    "    model : keras.Model, optional\n",
    "        Preloaded backbone. If None, a ResNet50(include_top=False, pooling='avg') is created.\n",
    "    exts : tuple of str\n",
    "        File extensions to include (without dot).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Columns:\n",
    "          - 'filepath': full path to image\n",
    "          - 'class': Empty\n",
    "          - 'embedding': numpy.ndarray of shape (2048,)\n",
    "    \"\"\"\n",
    "    # 1) Load model if not provided\n",
    "    if model is None:\n",
    "        model = ResNet50(weights='imagenet',\n",
    "                         include_top=False,\n",
    "                         pooling='avg')\n",
    "\n",
    "    records = []\n",
    "    # 2) For each image, create an embedding\n",
    "    for i, image_path in enumerate(image_list):\n",
    "        print(i)\n",
    "        try:\n",
    "            # load & preprocess\n",
    "            img = image.load_img(image_path)  # original size\n",
    "            x = image.img_to_array(img)\n",
    "            x = np.expand_dims(x, axis=0)\n",
    "            x = preprocess_input(x)\n",
    "            # get embedding\n",
    "            emb = model.predict(x, verbose=0).reshape(-1)  # (2048,)\n",
    "            # record\n",
    "            records.append({\n",
    "                'filepath': image_path,\n",
    "                'class': None,\n",
    "                'embedding': emb\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: could not process {image_path}: {e}\")\n",
    "\n",
    "    # 3) Pack into DataFrame\n",
    "    df = pd.DataFrame(records, columns=['filepath', 'class', 'embedding'])\n",
    "    return df\n",
    "\n",
    "\n",
    "super_folder = \"../IFCBpics/\"\n",
    "all_images = [os.path.join(root, f) for root, dirs, files in os.walk(super_folder) for f in files if \".png\" in f]\n",
    "df = get_image_embeddings(all_images)\n",
    "joblib.dump(df, \"../embedded_photos.pkl\")\n",
    "\n",
    "\n",
    "super_folder = \"../all_IFCBnets/\"\n",
    "all_images = [os.path.join(root, f) for root, dirs, files in os.walk(super_folder) for f in files if \".png\" in f]\n",
    "df = get_image_embeddings(all_images)\n",
    "joblib.dump(df, \"../embedded_photos_all.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e33172",
   "metadata": {},
   "source": [
    "## Task\n",
    "Apply the Random Forest model you trained before to these new images (or rather: image vectors). I'll provide you with some code to read in the RF model and the vectors. Please save the predictions in the object DataFrame df, in the column \"class\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69bac445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31merror\u001b[0m: \u001b[1mexternally-managed-environment\u001b[0m\r\n",
      "\r\n",
      "\u001b[31m×\u001b[0m This environment is externally managed\r\n",
      "\u001b[31m╰─>\u001b[0m To install Python packages system-wide, try apt install\r\n",
      "\u001b[31m   \u001b[0m python3-xyz, where xyz is the package you are trying to\r\n",
      "\u001b[31m   \u001b[0m install.\r\n",
      "\u001b[31m   \u001b[0m \r\n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Debian-packaged Python package,\r\n",
      "\u001b[31m   \u001b[0m create a virtual environment using python3 -m venv path/to/venv.\r\n",
      "\u001b[31m   \u001b[0m Then use path/to/venv/bin/python and path/to/venv/bin/pip. Make\r\n",
      "\u001b[31m   \u001b[0m sure you have python3-full installed.\r\n",
      "\u001b[31m   \u001b[0m \r\n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Debian packaged Python application,\r\n",
      "\u001b[31m   \u001b[0m it may be easiest to use pipx install xyz, which will manage a\r\n",
      "\u001b[31m   \u001b[0m virtual environment for you. Make sure you have pipx installed.\r\n",
      "\u001b[31m   \u001b[0m \r\n",
      "\u001b[31m   \u001b[0m See /usr/share/doc/python3.12/README.venv for more information.\r\n",
      "\r\n",
      "\u001b[1;35mnote\u001b[0m: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\r\n",
      "\u001b[1;36mhint\u001b[0m: See PEP 668 for the detailed specification.\r\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(\"../clfmodel.pkl\")\n",
    "df = joblib.load(\"../embedded_photos.pkl\")\n",
    "###or\n",
    "df = joblib.load(\"../embedded_photos_all.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd03711",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"class\"] = clf.predict(np.vstack(df[\"embedding\"].values))\n",
    "joblib.dump(df, \"../embedded_photos_labelled.pkl\")\n",
    "###or\n",
    "joblib.dump(df, \"../embedded_photos_all_labelled.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
